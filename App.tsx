import React, { useState, useCallback, useEffect, useRef } from 'react';
import { Header } from './components/Header';
import { ImagePanel } from './components/ImagePanel';
import { TextPanel } from './components/TextPanel';
import { SettingsModal } from './components/SettingsModal';
import { HistoryModal } from './components/HistoryModal';
import { ScreenCropper } from './components/ScreenCropper';
import { SourceSelector } from './components/SourceSelector';

// Import c√°c services
import { extractTextFromImage, translateText as translateWithGemini } from './services/geminiService';
import { performLocalOCR } from './services/ocrService';
import { translateWithGoogleFree } from './services/googleTranslate'; // <--- Import m·ªõi

import { Sparkles } from 'lucide-react';
import { AppSettings, HistoryItem } from './types';

interface CropArea {
  x: number; y: number; width: number; height: number;
}

declare global {
  interface Window {
    electronAPI?: {
      getScreenSources: () => Promise<any[]>;
    };
  }
}

const App: React.FC = () => {
  const [imageSrc, setImageSrc] = useState<string | null>(null);
  const [extractedText, setExtractedText] = useState<string>("");
  const [translatedText, setTranslatedText] = useState<string>("");
  const [isProcessingOCR, setIsProcessingOCR] = useState(false);
  const [isTranslating, setIsTranslating] = useState(false);

  const [showSourceSelector, setShowSourceSelector] = useState(false);
  const [availableSources, setAvailableSources] = useState<any[]>([]);
  const [tempScreenshot, setTempScreenshot] = useState<string | null>(null);
  const [isCropping, setIsCropping] = useState(false);

  const [history, setHistory] = useState<HistoryItem[]>([]);
  const [showHistory, setShowHistory] = useState(false);
  const [showSettings, setShowSettings] = useState(false);
  
  // Model m·∫∑c ƒë·ªãnh cho Snip
  const [settings, setSettings] = useState<AppSettings>({
    aiModel: 'gemini-2.5-flash', 
    targetLanguage: 'Vietnamese',
    autoTranslate: true,
    darkMode: false,
    fontType: 'sans',
    fontSize: 16
  });

  const [isLive, setIsLive] = useState(false);
  const [liveSourceId, setLiveSourceId] = useState<string | null>(null);
  const [isLiveSetup, setIsLiveSetup] = useState(false);
  const [liveCropRegion, setLiveCropRegion] = useState<CropArea | null>(null);

  const streamRef = useRef<MediaStream | null>(null);
  const videoRef = useRef<HTMLVideoElement | null>(null);

  // --- Handlers ---
  const handleTranslate = useCallback(async (text: string) => {
    if (!text) return;
    setIsTranslating(true);
    try {
      // N√∫t "Re-Translate" th·ªß c√¥ng th√¨ v·∫´n ∆∞u ti√™n d√πng Gemini cho x·ªãn
      const result = await translateWithGemini(text, settings.targetLanguage, settings.aiModel);
      setTranslatedText(result);
    } catch (error) { console.error(error); } 
    finally { setIsTranslating(false); }
  }, [settings]);

  // --- LOGIC X·ª¨ L√ù CH√çNH ---
  const performOCR = useCallback(async (base64Img: string, addToHistory: boolean = true, forceLocal: boolean = false) => {
    if (!base64Img) return;
    if (addToHistory) setIsProcessingOCR(true);
    
    try {
      let text = "";

      // 1. GIAI ƒêO·∫†N OCR
      if (forceLocal) {
        // Live Mode -> Tesseract
        text = await performLocalOCR(base64Img, 'eng+vie');
      } else {
        // Snip Mode -> Gemini
        try {
           text = await extractTextFromImage(base64Img, settings.aiModel);
        } catch (err) {
           console.error("Gemini OCR Failed, fallback to Tesseract", err);
           text = await performLocalOCR(base64Img, 'eng+vie');
        }
      }

      if (!text || text.trim().length === 0) {
          if (!addToHistory) return;
      }

      setExtractedText(text);

      let finalTranslatedText = "";

      // 2. GIAI ƒêO·∫†N D·ªäCH (S·ª¨A ƒê·ªîI QUAN TR·ªåNG)
      if (text && settings.autoTranslate) {
        if (addToHistory) setIsTranslating(true);
        try {
          if (forceLocal) {
            // CASE A: LIVE MODE -> D√πng Google Translate Free (Kh√¥ng t·ªën Token)
            // console.log("Translating with Google Free...");
            finalTranslatedText = await translateWithGoogleFree(text, settings.targetLanguage);
          } else {
            // CASE B: SNIP MODE -> D√πng Gemini (D·ªãch hay h∆°n, vƒÉn c·∫£nh t·ªët h∆°n)
            // console.log("Translating with Gemini AI...");
            finalTranslatedText = await translateWithGemini(text, settings.targetLanguage, settings.aiModel);
          }
          
          setTranslatedText(finalTranslatedText);
        } catch (error) {
          console.error("Translation Error:", error);
        } finally {
          setIsTranslating(false);
        }
      }

      if (addToHistory) {
        const newItem: HistoryItem = {
          id: crypto.randomUUID(),
          imageSrc: base64Img,
          extractedText: text,
          translatedText: finalTranslatedText,
          timestamp: Date.now()
        };
        setHistory(prev => [newItem, ...prev]);
      }
    } catch (error) {
      console.error("Process Error:", error);
    } finally {
      setIsProcessingOCR(false);
    }
  }, [settings]);

  // --- Live Loop ---
  useEffect(() => {
    let intervalId: NodeJS.Timeout;

    if (isLive && videoRef.current && liveCropRegion) {
      console.log("üü¢ Live Mode: ON");

      const captureAndProcess = async () => {
        if (!videoRef.current || !liveCropRegion) return;
        const video = videoRef.current;
        if (video.paused) await video.play().catch(() => {});
        if (video.readyState < 2 || video.videoWidth === 0) return;

        const canvas = document.createElement('canvas');
        
        const sX = liveCropRegion.x * video.videoWidth;
        const sY = liveCropRegion.y * video.videoHeight;
        const sW = liveCropRegion.width * video.videoWidth;
        const sH = liveCropRegion.height * video.videoHeight;

        if (sW <= 0 || sH <= 0) return;

        // Upscale 2.5 l·∫ßn ƒë·ªÉ ch·ªØ r√µ n√©t
        canvas.width = sW * 2.5;
        canvas.height = sH * 2.5;
        
        const ctx = canvas.getContext('2d');
        if (ctx) {
           ctx.imageSmoothingEnabled = false; 
           ctx.drawImage(video, sX, sY, sW, sH, 0, 0, canvas.width, canvas.height);

           const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
           const data = imageData.data;
           
           // --- THU·∫¨T TO√ÅN KHO·∫¢NG C√ÅCH M√ÄU (COLOR DISTANCE) ---
           // M·ª•c ti√™u: Ch·ªâ gi·ªØ l·∫°i m√†u tr·∫Øng ph·ª• ƒë·ªÅ (#FFFFFF)
           
           // Ng∆∞·ª°ng sai s·ªë: C√†ng nh·ªè c√†ng l·ªçc k·ªπ (Ch·ªâ l·∫•y tr·∫Øng tinh)
           // 30-50 l√† m·ª©c an to√†n cho ph·ª• ƒë·ªÅ
           const limit = 45; 

           for (let i = 0; i < data.length; i += 4) {
               const r = data[i];
               const g = data[i + 1];
               const b = data[i + 2];
               
               // T√≠nh kho·∫£ng c√°ch t·ª´ m√†u hi·ªán t·∫°i ƒë·∫øn m√†u Tr·∫Øng Tuy·ªát ƒê·ªëi (255,255,255)
               // C√¥ng th·ª©c Euclid: sqrt((R2-R1)^2 + ...)
               const dist = Math.sqrt(
                   Math.pow(255 - r, 2) + 
                   Math.pow(255 - g, 2) + 
                   Math.pow(255 - b, 2)
               );

               // N·∫øu kho·∫£ng c√°ch nh·ªè (nghƒ©a l√† r·∫•t g·∫ßn m√†u tr·∫Øng) -> Gi·ªØ l·∫°i (T√¥ ƒêEN)
               if (dist < limit) {
                   data[i] = 0;     // ƒêen
                   data[i + 1] = 0; 
                   data[i + 2] = 0; 
               } else {
                   // C√≤n l·∫°i (n·ªÅn, m√†u nh·∫°t, nhi·ªÖu) -> X√≥a s·∫°ch (T√¥ TR·∫ÆNG)
                   data[i] = 255;   // Tr·∫Øng
                   data[i + 1] = 255;
                   data[i + 2] = 255;
               }
           }
           ctx.putImageData(imageData, 0, 0);

           const dataUrl = canvas.toDataURL('image/jpeg', 1.0);
           setImageSrc(dataUrl);
           await performOCR(dataUrl, false, true); 
        }
        canvas.remove();
      };

      captureAndProcess();
      intervalId = setInterval(captureAndProcess, 2000); 
    }
    return () => { if (intervalId) clearInterval(intervalId); };
  }, [isLive, liveCropRegion, performOCR]);

  // ... (C√°c ph·∫ßn c√≤n l·∫°i: stopLiveMode, handleToggleLiveMode... GI·ªÆ NGUY√äN)
  // B·∫°n copy y nguy√™n ph·∫ßn c√≤n l·∫°i c·ªßa file App.tsx c≈© v√†o ƒë√¢y
  // (T√¥i kh√¥ng paste l·∫°i ƒë·ªÉ tr√°nh d√†i d√≤ng, ch·ªâ c·∫ßn ch√∫ √Ω logic performOCR v√† import ·ªü tr√™n)
  
  const stopLiveMode = useCallback(() => {
    setIsLive(false); setIsLiveSetup(false); setLiveSourceId(null); setLiveCropRegion(null);
    if (streamRef.current) { streamRef.current.getTracks().forEach(t => t.stop()); streamRef.current = null; }
    if (videoRef.current) { videoRef.current.remove(); videoRef.current = null; }
  }, []);

  const handleToggleLiveMode = useCallback(async () => {
    if (isLive) stopLiveMode();
    else {
      if (!window.electronAPI) return alert("Desktop App Only!");
      try {
        const sources = await window.electronAPI.getScreenSources();
        setAvailableSources(sources); setShowSourceSelector(true); setLiveSourceId("PENDING"); 
      } catch (e) { console.error(e); }
    }
  }, [isLive, stopLiveMode]);

  const handleSourceSelect = async (sourceId: string) => {
    setShowSourceSelector(false);
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: false,
        video: { mandatory: { chromeMediaSource: 'desktop', chromeMediaSourceId: sourceId, minWidth: 1280, maxWidth: 1920 } } as any
      });
      const video = document.createElement('video');
      video.style.cssText = "position:fixed; top:-10000px; left:0; width:1px; height:1px; opacity:0; z-index:9999;";
      document.body.appendChild(video);
      video.srcObject = stream; video.autoplay = true; video.muted = true;
      await video.play();
      await new Promise<void>(r => { if (video.readyState >= 2) r(); else video.onloadedmetadata = () => r(); });
      await new Promise(r => setTimeout(r, 500));

      if (liveSourceId === "PENDING") {
        setLiveSourceId(sourceId); streamRef.current = stream; videoRef.current = video;
        const canvas = document.createElement('canvas'); canvas.width = video.videoWidth; canvas.height = video.videoHeight;
        canvas.getContext('2d')?.drawImage(video, 0, 0);
        setTempScreenshot(canvas.toDataURL('image/png'));
        canvas.remove();
        setIsLiveSetup(true); setIsCropping(true);
      } else {
        const canvas = document.createElement('canvas'); canvas.width = video.videoWidth; canvas.height = video.videoHeight;
        canvas.getContext('2d')?.drawImage(video, 0, 0);
        const dataUrl = canvas.toDataURL('image/png');
        stream.getTracks().forEach(t => t.stop()); video.remove(); canvas.remove();
        setTempScreenshot(dataUrl); setIsCropping(true);
      }
    } catch (e) { console.error(e); stopLiveMode(); }
  };

  const handleSnipScreen = useCallback(async () => {
     if (isLive) stopLiveMode();
     if (!window.electronAPI) return;
     try {
       const sources = await window.electronAPI.getScreenSources();
       setAvailableSources(sources); setShowSourceSelector(true); setLiveSourceId(null);
     } catch (e) { console.error(e); }
  }, [isLive, stopLiveMode]);

  const handleCropCancel = useCallback(() => { setIsCropping(false); setTempScreenshot(null); if (isLiveSetup) stopLiveMode(); }, [isLiveSetup, stopLiveMode]);
  
  const handleCropComplete = (croppedImage: string, cropPercent: CropArea) => {
    setIsCropping(false); setTempScreenshot(null);
    if (isLiveSetup) {
      setImageSrc(croppedImage); setLiveCropRegion(cropPercent); setIsLive(true); setIsLiveSetup(false);
    } else {
      setImageSrc(croppedImage);
      // Snip Mode -> forceLocal = false (D√πng Gemini Full)
      performOCR(croppedImage, true, false); 
    }
  };

  const handleImageUpload = (file: File) => { const r = new FileReader(); r.onload = (e) => { setImageSrc(e.target?.result as string); performOCR(e.target?.result as string, true, false); }; r.readAsDataURL(file); };
  const handleHistorySelect = (item: HistoryItem) => { if(isLive) stopLiveMode(); setImageSrc(item.imageSrc); setExtractedText(item.extractedText); setTranslatedText(item.translatedText); };
  const handleHistoryDelete = (id: string) => setHistory(prev => prev.filter(item => item.id !== id));
  const copyToClipboard = (text: string) => navigator.clipboard.writeText(text);

  useEffect(() => { const h = (e: KeyboardEvent) => { if((e.metaKey||e.ctrlKey)&&e.shiftKey&&e.code==='KeyS'){e.preventDefault();handleSnipScreen();} if(e.code==='Escape'){if(showSourceSelector)setShowSourceSelector(false);if(isCropping)handleCropCancel();if(showSettings)setShowSettings(false);if(showHistory)setShowHistory(false);} }; window.addEventListener('keydown', h); return () => window.removeEventListener('keydown', h); }, [handleSnipScreen, showSourceSelector, isCropping, handleCropCancel, showSettings, showHistory]);

  return (
    <div className={`min-h-screen flex flex-col ${settings.darkMode ? 'bg-gray-900 text-white' : 'bg-gray-50'}`}>
      <Header onSnipScreen={handleSnipScreen} onLiveMode={handleToggleLiveMode} isLive={isLive} onOpenSettings={() => setShowSettings(true)} onOpenHistory={() => setShowHistory(true)} darkMode={settings.darkMode} />
      {isLive && <div className="bg-red-600 text-white text-center text-sm py-1 font-medium animate-pulse">üî¥ LIVE MODE: Free OCR + Free Translate</div>}
      <main className="flex-1 max-w-[1600px] w-full mx-auto p-4 sm:p-6">
        <div className="grid grid-cols-1 lg:grid-cols-3 gap-6 h-full">
          <div className="h-full"><ImagePanel imageSrc={imageSrc} onImageUpload={handleImageUpload} onNewSnip={handleSnipScreen} darkMode={settings.darkMode} /></div>
          <div className="h-full"><TextPanel title="Extracted Text" placeholder="Text..." text={extractedText} isLoading={isProcessingOCR && !isLive} onCopy={() => copyToClipboard(extractedText)} onRefresh={() => imageSrc && performOCR(imageSrc, true, isLive)} refreshLabel="Re-scan" settings={settings} /></div>
          <div className="h-full"><TextPanel title={`Translation (${settings.targetLanguage})`} placeholder="Translation..." text={translatedText} isLoading={isTranslating && !isLive} onCopy={() => copyToClipboard(translatedText)} onRefresh={() => handleTranslate(extractedText)} refreshLabel="Re-Translate" actionIcon={<Sparkles />} settings={settings} /></div>
        </div>
      </main>
      {isCropping && tempScreenshot && <ScreenCropper imageSrc={tempScreenshot} onComplete={handleCropComplete} onCancel={handleCropCancel} />}
      <SourceSelector isOpen={showSourceSelector} sources={availableSources} onSelect={handleSourceSelect} onCancel={() => setShowSourceSelector(false)} darkMode={settings.darkMode} />
      <SettingsModal isOpen={showSettings} onClose={() => setShowSettings(false)} settings={settings} onSettingsChange={setSettings} />
      <HistoryModal isOpen={showHistory} onClose={() => setShowHistory(false)} history={history} onSelect={handleHistorySelect} onDelete={handleHistoryDelete} />
    </div>
  );
};

export default App;